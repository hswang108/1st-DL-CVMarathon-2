{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 嘗試用 keras 的 DepthwiseConv2D 等 layers 實做 Inverted Residual Block.\n",
    "   - depthwise's filter shape 爲 (3,3), padding = same\n",
    "   - 不需要給 alpha, depth multiplier 參數\n",
    "   - expansion 因子爲 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.models import Input, Model\n",
    "from keras.layers import DepthwiseConv2D, Conv2D, BatchNormalization, ReLU, Add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 原始的Residual Block是先降維->Conv->升維->相加\n",
    "#### Inverted Residual Block是先升維->Conv->降維->相加 (多channels減少information loss)\n",
    "<img src=\"Inverted_residuals.png\" width=\"400\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bottleneck最後輸出用Linear反而比ReLU效果好\n",
    "#### Bottleneck 與 Bottleneck相互連結效果最佳\n",
    "<img src=\"Ablation.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 定義 Separable Convolution 函數 (請在此實做)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def InvertedRes(input, expansion):\n",
    "\n",
    "    # Expansion Layer\n",
    "    x = Conv2D(expansion*K.int_shape(input)[-1], (1,1), padding='same')(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU(max_value=6)(x)\n",
    "    \n",
    "    # Depthwise Convolution (bias可有可無)\n",
    "    x = DepthwiseConv2D((3,3), padding='same', depth_multiplier=1, use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU(max_value=6)(x)\n",
    "    \n",
    "    # Pointwise Convolution\n",
    "    x = Conv2D(3, (1,1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = ReLU()(x)\n",
    "    \n",
    "    # Add Layer\n",
    "    added = Add()([input, x])\n",
    "    \n",
    "    return added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 建構模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/yanroo/anaconda3/envs/Keras/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 18)   72          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 18)   72          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 64, 64, 18)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_1 (DepthwiseCo (None, 64, 64, 18)   162         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 18)   72          depthwise_conv2d_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 64, 64, 18)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 3)    57          re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 3)    12          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 64, 3)    0           input_1[0][0]                    \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 447\n",
      "Trainable params: 369\n",
      "Non-trainable params: 78\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input((64, 64, 3))\n",
    "output = InvertedRes(input, 6)\n",
    "model = Model(inputs=input, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"MobilenetV2.png\" width=\"400\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_3",
   "language": "python",
   "name": "keras_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
